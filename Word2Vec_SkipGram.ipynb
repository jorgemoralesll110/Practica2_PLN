{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Word2Vec / Skip-gram Practice (Full Execution from Notebook)\n",
    "\n",
    "This notebook runs the **entire Word2Vec pipeline** by calling a single function from the modular `w2v` package.  \n",
    "Each step is briefly explained below."
   ],
   "id": "fe2c1af5ad8a8797"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:29:51.402451Z",
     "start_time": "2025-11-07T19:29:51.388238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "\n",
    "base_dir = \"C:/Users/tomas/Desktop/PLN/PRACTICA 2/Practica2_PLN\"\n",
    "sys.path.insert(0, os.path.join(base_dir))\n",
    "sys.path.insert(0, os.path.join(base_dir, 'w2v'))\n",
    "print('Base directory:', base_dir)"
   ],
   "id": "bf239a05a866da13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:/Users/tomas/Desktop/PLN/PRACTICA 2/Practica2_PLN\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Running the full pipeline\n",
    "The `run_pipeline()` function performs:\n",
    "1. Corpus loading and tokenization  \n",
    "2. Vocabulary building  \n",
    "3. (center, context) pair generation  \n",
    "4. Model training  \n",
    "5. Analysis of nearest neighbors and analogies"
   ],
   "id": "b89a47ec62027009"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T19:30:08.481816Z",
     "start_time": "2025-11-07T19:29:51.478884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from word2vec.main import run_program\n",
    "\n",
    "corpus_path = os.path.join(base_dir, 'resources', 'dataset_word2vec.txt')\n",
    "if not os.path.exists(corpus_path):\n",
    "    sample = [\n",
    "        \"París es la capital de Francia\",\n",
    "        \"Madrid es la capital de España\",\n",
    "        \"el perro ladra en la casa\",\n",
    "        \"el gato maúlla en la silla\",\n",
    "        \"el coche del conductor está en la calle\"\n",
    "    ]\n",
    "    os.makedirs(os.path.dirname(corpus_path), exist_ok=True)\n",
    "    with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(sample))\n",
    "    print(\"Sample corpus created at:\", corpus_path)\n",
    "\n",
    "model, vocab, inv_vocab, pairs = run_program(\n",
    "    corpus_path=corpus_path,\n",
    "    window_size=2,\n",
    "    embedding_dim=50,\n",
    "    learning_rate=0.05,\n",
    "    epochs=100,\n",
    "    min_count=1\n",
    ")"
   ],
   "id": "ef8dbe17a62dfce0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "WORD2VEC - EJECUCIÓN DEL PROGRAMA MEDIANTE SKIP-GRAM\n",
      "**********************************************************************\n",
      "\n",
      " Primer paso) Cargar y tokenizar el corpus\n",
      "\n",
      " Segundo paso) Construir el vocabulario\n",
      "Tamaño del vocabulario: 356\n",
      "Top 10 palabras: [('la', 131), ('el', 129), ('es', 37), ('está', 27), ('en', 26), ('un', 20), ('por', 15), ('una', 15), ('al', 14), ('gato', 11)]\n",
      "\n",
      " Tercer paso) Generar el par 'Centro-Contexto'\n",
      "Total pairs: 2440\n",
      "\n",
      " Cuarto paso) Entrenar el modelo Skip-Gram\n",
      "Epoch 10/100: Loss: 4.1203\n",
      "Epoch 20/100: Loss: 3.2734\n",
      "Epoch 30/100: Loss: 2.8909\n",
      "Epoch 40/100: Loss: 2.7477\n",
      "Epoch 50/100: Loss: 2.6983\n",
      "Epoch 60/100: Loss: 2.6871\n",
      "Epoch 70/100: Loss: 2.6779\n",
      "Epoch 80/100: Loss: 2.6686\n",
      "Epoch 90/100: Loss: 2.6606\n",
      "Epoch 100/100: Loss: 2.6566\n",
      "\n",
      "**********************************************************************\n",
      "ANÁLISIS DE LOS EMBEDDINGS\n",
      "**********************************************************************\n",
      "\n",
      " ********** VECINOS MÁS CERCANOS **********\n",
      "\n",
      "'perro':\n",
      "  - gato: 0.7764\n",
      "  - hermano: 0.7044\n",
      "  - ratón: 0.6862\n",
      "  - invierno: 0.6647\n",
      "  - verano: 0.6454\n",
      "\n",
      "'gato':\n",
      "  - ratón: 0.7872\n",
      "  - perro: 0.7764\n",
      "  - hermano: 0.6901\n",
      "  - invierno: 0.6628\n",
      "  - profesor: 0.6500\n",
      "\n",
      "'coche':\n",
      "  - verano: 0.8480\n",
      "  - invierno: 0.8470\n",
      "  - profesor: 0.8429\n",
      "  - conductor: 0.8218\n",
      "  - autobús: 0.7463\n",
      "\n",
      "'parís':\n",
      "  - roma: 0.9982\n",
      "  - madrid: 0.9980\n",
      "  - francia: 0.8832\n",
      "  - españa: 0.8738\n",
      "  - italia: 0.8608\n",
      "\n",
      "'francia':\n",
      "  - españa: 0.9982\n",
      "  - italia: 0.9961\n",
      "  - roma: 0.8909\n",
      "  - madrid: 0.8889\n",
      "  - parís: 0.8832\n",
      "\n",
      "'niña':\n",
      "  - madre: 0.7874\n",
      "  - hermana: 0.7488\n",
      "  - niño: 0.7196\n",
      "  - canción: 0.6319\n",
      "  - médica: 0.6097\n",
      "\n",
      "'agua':\n",
      "  - camarero: 0.5909\n",
      "  - nosotros: 0.5658\n",
      "  - nosotras: 0.5632\n",
      "  - parque: 0.5273\n",
      "  - marrón: 0.5264\n",
      "\n",
      "'casa':\n",
      "  - ciudad: 0.7541\n",
      "  - mochila: 0.7524\n",
      "  - montaña: 0.7504\n",
      "  - fuente: 0.7494\n",
      "  - profesora: 0.7304\n",
      "\n",
      "'profesor':\n",
      "  - invierno: 0.9967\n",
      "  - verano: 0.9952\n",
      "  - coche: 0.8429\n",
      "  - alumno: 0.8295\n",
      "  - rápido: 0.7538\n",
      "\n",
      "'médico':\n",
      "  - enfermero: 0.8634\n",
      "  - enfermera: 0.7047\n",
      "  - ratón: 0.6672\n",
      "  - alumno: 0.6612\n",
      "  - médica: 0.6481\n",
      "\n",
      "**********************************************************************\n",
      "ANÁLISIS DE LAS ANALOGÍAS\n",
      "\n",
      "parís : francia :: madrid : ?\n",
      "     - españa : 0.9949\n",
      "     - italia : 0.9938\n",
      "     - roma : 0.8791\n",
      "\n",
      "perro : ladra :: gato : ?\n",
      "     - persigue : 0.7427\n",
      "     - fuego : 0.5678\n",
      "     - bombero : 0.5659\n",
      "\n",
      "niño : niña :: profesor : ?\n",
      "     - profesora : 0.9148\n",
      "     - bicicleta : 0.9119\n",
      "     - camiseta : 0.9098\n",
      "\n",
      "médico : médico :: médica : ?\n",
      "     - escuela : 0.7417\n",
      "     - estación : 0.7255\n",
      "     - madre : 0.7220\n",
      "\n",
      "**********************************************************************\n",
      "HIPERPARÁMETROS USADOS:\n",
      "    - Tamaño de la ventana: 2\n",
      "    - Dimensión del embedding: 50\n",
      "    - Tasa de aprendizaje: 0.05\n",
      "    - Épocas: 100\n",
      "    - Frecuencia mínima: 1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "    ",
   "id": "f999565c4f757c88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eced24862043bac6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
