{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:25:27.685649Z",
     "start_time": "2026-01-14T19:25:27.169136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "from word2vec.main import run_program"
   ],
   "id": "e734df18a0c4cdeb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Word2Vec con Skip-Gram: implementación y análisis\n",
    "\n",
    "En este trabajo he implementado desde cero un modelo Word2Vec basado en Skip-Gram con el objetivo de entender su funcionamiento interno. Se ha trabajado con un corpus controlado, diseñado para contener patrones lingüísticos claros como relaciones de género gramatical, asociaciones entre agentes y acciones, y relaciones geográficas simples.\n",
    "\n",
    "Se ha utilizado softmax completo sobre todo el vocabulario, siendo consciente de su coste computacional, porque permite seguir de forma directa la función objetivo original y analizar con claridad el proceso de entrenamiento. Alternativas más eficientes como Negative Sampling no se han incluido para priorizar la comprensión conceptual del modelo.\n",
    "\n",
    "La evaluación combina un análisis cuantitativo, mediante la pérdida final y la similitud media entre palabras y sus vecinos más cercanos, con un análisis cualitativo basado en vecinos y analogías no triviales, diseñadas en función del contenido del corpus. Los resultados muestran que el modelo captura regularidades distribucionales básicas, aunque también evidencian las limitaciones derivadas del tamaño del corpus."
   ],
   "id": "fe2c1af5ad8a8797"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:25:31.402183Z",
     "start_time": "2026-01-14T19:25:31.391927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd()))\n",
    "sys.path.insert(0, os.path.join(base_dir))\n",
    "sys.path.insert(0, os.path.join(base_dir, 'w2v'))\n",
    "print('Base directory:', base_dir)"
   ],
   "id": "bf239a05a866da13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: C:\\Users\\ralme\\OneDrive\\Escritorio\\4_GCID\\Asignaturas\\PLN\\Practica2_PLN\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Estructura del proyecto\n",
    "\n",
    "1. Configuración del entorno y carga del corpus  \n",
    "2. Ejecución del pipeline completo de Word2Vec  \n",
    "3. Evaluación cuantitativa de los embeddings  \n",
    "4. Análisis cualitativo: vecinos y analogías  "
   ],
   "id": "b89a47ec62027009"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-14T19:09:22.671810Z",
     "start_time": "2026-01-14T19:09:18.579651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_path = os.path.join(base_dir, 'resources', 'dataset_word2vec.txt')\n",
    "if not os.path.exists(corpus_path):\n",
    "    sample = [\n",
    "        \"París es la capital de Francia\",\n",
    "        \"Madrid es la capital de España\",\n",
    "        \"el perro ladra en la casa\",\n",
    "        \"el gato maúlla en la silla\",\n",
    "        \"el coche del conductor está en la calle\"\n",
    "    ]\n",
    "    os.makedirs(os.path.dirname(corpus_path), exist_ok=True)\n",
    "    with open(corpus_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(sample))\n",
    "    print(\"Sample corpus created at:\", corpus_path)\n",
    "\n",
    "model, vocab, inv_vocab, pairs = run_program(\n",
    "    corpus_path=corpus_path,\n",
    "    window_size=2,\n",
    "    embedding_dim=50,\n",
    "    learning_rate=0.05,\n",
    "    epochs=100,\n",
    "    min_count=1\n",
    ")"
   ],
   "id": "ef8dbe17a62dfce0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "WORD2VEC - EJECUCIÓN DEL PROGRAMA MEDIANTE SKIP-GRAM\n",
      "**********************************************************************\n",
      "\n",
      " Primer paso) Cargar y tokenizar el corpus\n",
      "\n",
      " Segundo paso) Construir el vocabulario\n",
      "Tamaño del vocabulario: 355\n",
      "Top 10 palabras: [('la', 131), ('el', 129), ('es', 37), ('está', 27), ('en', 26), ('un', 20), ('por', 15), ('una', 15), ('al', 14), ('gato', 11)]\n",
      "\n",
      " Tercer paso) Generar el par 'Centro-Contexto'\n",
      "Total pairs: 2413\n",
      "\n",
      " Cuarto paso) Entrenar el modelo Skip-Gram\n",
      "\n",
      " Quinto paso) Evaluación cuantitativa de los embeddings\n",
      "Average neighbor similarity: 0.9522\n",
      "\n",
      "**********************************************************************\n",
      "ANÁLISIS DE LOS EMBEDDINGS\n",
      "**********************************************************************\n",
      "\n",
      " ********** VECINOS MÁS CERCANOS **********\n",
      "\n",
      "'perro':\n",
      "  - gato: 0.9829\n",
      "  - en: 0.9591\n",
      "  - tren: 0.9478\n",
      "  - coche: 0.9471\n",
      "  - está: 0.9449\n",
      "\n",
      "'gato':\n",
      "  - perro: 0.9829\n",
      "  - en: 0.9564\n",
      "  - coche: 0.9513\n",
      "  - tren: 0.9509\n",
      "  - parque: 0.9477\n",
      "\n",
      "'coche':\n",
      "  - gato: 0.9513\n",
      "  - perro: 0.9471\n",
      "  - vuela: 0.9431\n",
      "  - en: 0.9405\n",
      "  - es: 0.9385\n",
      "\n",
      "'parís':\n",
      "  - dos: 0.4178\n",
      "  - llave: 0.3736\n",
      "  - grande: 0.3724\n",
      "  - camino: 0.3649\n",
      "  - lejos: 0.3526\n",
      "\n",
      "'francia':\n",
      "  - el: 0.5440\n",
      "  - vaso: 0.3929\n",
      "  - tranquilo: 0.3793\n",
      "  - duerme: 0.3727\n",
      "  - caliente: 0.3355\n",
      "\n",
      "'niña':\n",
      "  - por: 0.9609\n",
      "  - perra: 0.9521\n",
      "  - está: 0.9456\n",
      "  - madre: 0.9409\n",
      "  - gata: 0.9389\n",
      "\n",
      "'agua':\n",
      "  - cierra: 0.7164\n",
      "  - pájaro: 0.6984\n",
      "  - ayuda: 0.6961\n",
      "  - ordenador: 0.6862\n",
      "  - coche: 0.6857\n",
      "\n",
      "'casa':\n",
      "  - ciudad: 0.9562\n",
      "  - pelota: 0.9558\n",
      "  - mañana: 0.9497\n",
      "  - por: 0.9451\n",
      "  - es: 0.9448\n",
      "\n",
      "'profesor':\n",
      "  - café: 0.4338\n",
      "  - persigue: 0.4171\n",
      "  - periódico: 0.3966\n",
      "  - médico: 0.3962\n",
      "  - escucha: 0.3906\n",
      "\n",
      "'médico':\n",
      "  - avión: 0.5672\n",
      "  - teléfono: 0.5208\n",
      "  - persigue: 0.5106\n",
      "  - gusta: 0.5025\n",
      "  - pasea: 0.4898\n",
      "\n",
      "**********************************************************************\n",
      "ANÁLISIS DE LAS ANALOGÍAS\n",
      "\n",
      "parís : francia :: madrid : ?\n",
      "     - seca : 0.3069\n",
      "     - ingeniera : 0.2905\n",
      "     - tranquilo : 0.2775\n",
      "\n",
      "perro : ladra :: gato : ?\n",
      "     - pan : 0.5886\n",
      "     - cierra : 0.5858\n",
      "     - gusta : 0.5618\n",
      "\n",
      "niño : niña :: profesor : ?\n",
      "     - gata : 0.7873\n",
      "     - madre : 0.7868\n",
      "     - perra : 0.7837\n",
      "\n",
      "**********************************************************************\n",
      "HIPERPARÁMETROS USADOS:\n",
      "    - Tamaño de la ventana: 2\n",
      "    - Dimensión del embedding: 50\n",
      "    - Tasa de aprendizaje: 0.05\n",
      "    - Épocas: 100\n",
      "    - Frecuencia mínima: 1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusiones\n",
    "\n",
    "Los resultados obtenidos indican que el modelo es capaz de aprender relaciones básicas entre las palabras a partir de su uso en el corpus. En las palabras más frecuentes, los vecinos más cercanos suelen tener un significado relacionado, y las analogías planteadas permiten observar relaciones sencillas como el género gramatical, acciones asociadas a personas o animales y algunas relaciones geográficas simples.\n",
    "\n",
    "El análisis realizado muestra también que el entrenamiento funciona de forma adecuada y que la elección de ciertos parámetros, como el tamaño de la ventana o la dimensión del embedding, influye en la calidad de los resultados. En general, configuraciones con embeddings algo más grandes tienden a ofrecer representaciones más coherentes, aunque esto implica un mayor coste de cálculo.\n",
    "\n",
    "Al mismo tiempo, el trabajo pone de manifiesto algunas limitaciones. El uso de softmax completo hace que el entrenamiento sea más costoso y poco escalable a corpus grandes, y el tamaño limitado del corpus utilizado condiciona la fiabilidad de analogías más complejas. Estas limitaciones son esperables dado el enfoque del trabajo y el contexto académico en el que se ha desarrollado.\n",
    "\n",
    "Como posible continuación, se podrían incorporar técnicas más eficientes para el entrenamiento, como Negative Sampling, o utilizar corpus más amplios que permitan evaluar el modelo en escenarios más realistas.\n"
   ],
   "id": "2324761703b7a703"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
